{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Weights and Biases](https://www.wandb.com/) is a tool for visualizing and tracking machine learning experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import abilities\n",
    "from ai import Chat, Vision, Audio, Images, Embeddings, FineTuner\n",
    "import powers\n",
    "import wandb\n",
    "import time\n",
    "from datetime import datetime\n",
    "import wandb_logging as wb\n",
    "\n",
    "# Adjust model globally here or modify in function calls. Vision model cannot be changed, for now ;) \n",
    "model = \"gpt-3.5-turbo-1106\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_all_spans(span, name):\n",
    "    # Log the current span\n",
    "    span.log(name=name)\n",
    "\n",
    "    for attribute, value in vars(span._span).items():\n",
    "        if attribute == \"child_spans\":\n",
    "            print(f\"{attribute}: {len(value)}\")\n",
    "            for child_span in value:\n",
    "                print(f\"    {child_span}\")\n",
    "\n",
    "    # Access the child_spans attribute of the span object, if it exists\n",
    "    child_spans = getattr(span._span, 'child_spans', [])\n",
    "    \n",
    "    # Check if child_spans is not empty\n",
    "    if child_spans:\n",
    "        # Iterate over each child span\n",
    "        for child_span in child_spans:\n",
    "            # Construct the Trace object with _model_dict set to None and _span set to the child_span object\n",
    "            trace = span\n",
    "            # Log the Trace object\n",
    "            trace.log(name=name)\n",
    "\n",
    "## figure out how to construct the trace object for the nested spans\n",
    "## figure out how to log the trace object\n",
    "## we want a single log_all_spans function for the end of an application run to log everything to wandb.\n",
    "## could handle the multiagent case by having a method which updates the end time of the child spans in the chain leading to the current span\n",
    "## is it possible to have it such that the user only has to include the parent span, and all the orchestration is automatically handled? Perhaps using metadata?\n",
    "\n",
    "## Adding images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights and Biases x OpenAI-Launchpad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using wandb prompts and traces to visualize the flow in AI systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = Audio()\n",
    "chat = Chat(model=model, system=\"Helpful assistant.\")\n",
    "\n",
    "wandb.init(project=\"openai-launchpad\") ## Initialize wandb project\n",
    "\n",
    "chain_name = \"conversation\"\n",
    "\n",
    "chain_span , _ , _ = wb.wandb_span(span_kind = \"agent\", span_name=chain_name, parent_span=None, root_span=None)\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    # transcript = audio.record_and_transcribe()\n",
    "    transcript = \"This is a test.\"\n",
    "    time.sleep(1)\n",
    "\n",
    "    transcript_span, _ , chain_span = wb.wandb_span(\n",
    "        span_kind=\"tool\",\n",
    "        span_name=\"transcription\",\n",
    "        inputs={\"audio\": \"audio\"},\n",
    "        outputs={\"transcript\": transcript},\n",
    "        parent_span=None,\n",
    "        root_span=chain_span,\n",
    "    )\n",
    "\n",
    "    if \"quit\" in transcript:\n",
    "        break\n",
    "\n",
    "    completion, messages = chat.chat_completion(transcript, speak=False, stream=True, memories=True)\n",
    "\n",
    "    # Log the LLM used.\n",
    "    llm_span, _ ,  chain_span = wb.wandb_span(\n",
    "        span_kind=\"llm\",\n",
    "        span_name=\"chat\",\n",
    "        inputs={\"transcript\": transcript},\n",
    "        outputs={\"completion\": completion, \"messages\": messages},\n",
    "        parent_span = None,\n",
    "        root_span=chain_span,\n",
    "    )\n",
    "\n",
    "    voice = \"echo\"\n",
    "    # audio.speak(completion, voice=voice)\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Log the speech span.\n",
    "    speech_span, llm_span , chain_span = wb.wandb_span(\n",
    "        span_kind=\"tool\",\n",
    "        span_name=\"speech\",\n",
    "        inputs={\"completion\": completion},\n",
    "        outputs={\"tool\": \"Completion spoken.\"},\n",
    "        parent_span=llm_span,\n",
    "        root_span=chain_span,\n",
    "        metadata={\"voice\": voice}\n",
    "    )\n",
    "\n",
    "conversation_end_time_ms = round(datetime.now().timestamp() * 1000)\n",
    "chain_span.end_time_ms = conversation_end_time_ms\n",
    "\n",
    "# log_all_spans(chain_span, chain_name)\n",
    "\n",
    "chain_span.log(name=chain_name)\n",
    "\n",
    "# End wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attribute, value in vars(chain_span._span).items():\n",
    "    if attribute == \"child_spans\":\n",
    "        print(f\"{attribute}: {len(value)}\")\n",
    "        for child_span in value:\n",
    "            print(f\"    {child_span}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wandb project\n",
    "wandb.init(project=\"openai-launchpad\")\n",
    "\n",
    "# Define the chain name for logging\n",
    "chain_name = \"image_generation_and_vision\"\n",
    "\n",
    "image_prompt = \"The power of time in the palm of your hand.\"\n",
    "\n",
    "# Start the chain for logging\n",
    "chain_span, _ , _ = wb.wandb_span(span_kind=\"chain\", span_name=chain_name, parent_span=None, root_span=None)\n",
    "\n",
    "# Generate an image\n",
    "images = Images()\n",
    "response, path = images.generate_image(image_prompt, display_image=True, save_image=True)\n",
    "\n",
    "# Log the image generation span\n",
    "image_gen_span, _ , chain_span = wb.wandb_span(\n",
    "    span_kind=\"tool\",\n",
    "    span_name=\"image_generation\",\n",
    "    inputs={\"prompt\": image_prompt},\n",
    "    outputs={\"response\": response, \"image_path\": path},\n",
    "    parent_span=None,\n",
    "    root_span=chain_span,\n",
    "    metadata={\"display_image\": True, \"save_image\": True}\n",
    ")\n",
    "\n",
    "# Vision system analysis\n",
    "vision = Vision(system=\"You can only respond with bullet points.\")\n",
    "response, messages = vision.vision_completion(prompt=\"What is this image showing?\", image_paths=[path], memories=True, stream=True)\n",
    "\n",
    "# Log the vision system span\n",
    "vision_span, _ , chain_span = wb.wandb_span(\n",
    "    span_kind=\"llm\",\n",
    "    span_name=\"vision_description\",\n",
    "    inputs={\"prompt\": \"What is this image showing?\", \"image_paths\": [path]},\n",
    "    outputs={\"response\": response, \"messages\": messages},\n",
    "    parent_span=None,\n",
    "    root_span=chain_span\n",
    ")\n",
    "\n",
    "chain_span.log(name=chain_name)\n",
    "\n",
    "# End wandb run\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-launchpad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
