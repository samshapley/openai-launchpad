{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Weights and Biases](https://www.wandb.com/) is a tool for visualizing and tracking machine learning experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import abilities\n",
    "from ai import Chat, Vision, Audio, Images, Embeddings, FineTuner\n",
    "import wandb\n",
    "import time\n",
    "from wandb_logging import WandbSpanManager\n",
    "\n",
    "# Adjust model globally here or modify in function calls. Vision model cannot be changed, for now ;) \n",
    "model = \"gpt-3.5-turbo-1106\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights and Biases x OpenAI-Launchpad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using wandb prompts and traces to visualize the flow in AI systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = WandbSpanManager(name=\"system\")\n",
    "\n",
    "wandb.init(project=\"openai-launchpad\") ## Initialize wandb project\n",
    "\n",
    "audio = Audio()\n",
    "chat = Chat(model=model, system=\"Helpful assistant.\")\n",
    "\n",
    "chain_name = \"conversation\"\n",
    "\n",
    "agent_name = \"agent\"\n",
    "\n",
    "agent_span = wb.wandb_span(span_kind = \"LLM\", span_name=agent_name, parent_span_id=None)\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    chain_span = wb.wandb_span(span_kind = \"chain\", span_name=chain_name, parent_span_id=agent_span)\n",
    "\n",
    "    # transcript = audio.record_and_transcribe()\n",
    "    transcript = \"This is a test.\"\n",
    "    time.sleep(1)\n",
    "\n",
    "    transcript_span = wb.wandb_span(\n",
    "        span_kind=\"tool\",\n",
    "        span_name=\"transcription\",\n",
    "        parent_span_id=chain_span,\n",
    "        inputs={\"audio\": \"audio\"},\n",
    "        outputs={\"transcript\": transcript},\n",
    "    )\n",
    "\n",
    "    if \"quit\" in transcript:\n",
    "        break\n",
    "\n",
    "    completion, messages = chat.chat_completion(transcript, speak=False, stream=True, memories=True)\n",
    "\n",
    "    # Log the LLM used.\n",
    "    llm_span = wb.wandb_span(\n",
    "        span_kind=\"llm\",\n",
    "        span_name=\"chat\",\n",
    "        parent_span_id = chain_span,\n",
    "        inputs={\"transcript\": transcript},\n",
    "        outputs={\"completion\": completion, \"messages\": messages},\n",
    "        metadata={\"model\": model},\n",
    "    )\n",
    "\n",
    "    voice = \"echo\"\n",
    "    # audio.speak(completion, voice=voice)\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Log the speech span.\n",
    "    speech_span = wb.wandb_span(\n",
    "        span_kind=\"tool\",\n",
    "        span_name=\"speech\",\n",
    "        parent_span_id = llm_span,\n",
    "        inputs={\"completion\": completion},\n",
    "        outputs={\"tool\": \"Completion spoken.\"},\n",
    "        metadata={\"voice\": voice}\n",
    "    )\n",
    "\n",
    "wb.update_span_by_id(agent_span, inputs={\"transcript\": transcript, \"test\": \"test\"}, outputs={\"completion\": completion, \"messages\": messages})\n",
    "\n",
    "wb.log_top_level_span()\n",
    "\n",
    "# End wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = WandbSpanManager(name=\"image_generation_and_vision\")\n",
    "\n",
    "# Initialize wandb project\n",
    "wandb.init(project=\"openai-launchpad\")\n",
    "\n",
    "image_prompt = \"The power of time in the palm of your hand.\"\n",
    "\n",
    "# Start the chain for logging\n",
    "chain_span = wb.wandb_span(span_kind=\"chain\", span_name=\"image_generation_and_vision\", parent_span_id=None)\n",
    "\n",
    "# Generate an image\n",
    "images = Images()\n",
    "response, path = images.generate_image(image_prompt, display_image=True, save_image=True)\n",
    "\n",
    "# Log the image generation span\n",
    "image_gen_span = wb.wandb_span(\n",
    "    span_kind=\"tool\",\n",
    "    span_name=\"image_generation\",\n",
    "    inputs={\"prompt\": image_prompt},\n",
    "    outputs={\"response\": response, \"image_path\": path},\n",
    "    parent_span_id=chain_span,\n",
    "    metadata={\"display_image\": True, \"save_image\": True}\n",
    ")\n",
    "\n",
    "# Vision system analysis\n",
    "vision = Vision(system=\"You can only respond with bullet points.\")\n",
    "response, messages = vision.vision_completion(prompt=\"What is this image showing?\", image_paths=[path], memories=True, stream=True)\n",
    "\n",
    "# Log the vision system span\n",
    "vision_span = wb.wandb_span(\n",
    "    span_kind=\"llm\",\n",
    "    span_name=\"vision_description\",\n",
    "    inputs={\"prompt\": \"What is this image showing?\", \"image_paths\": [path]},\n",
    "    outputs={\"response\": response, \"messages\": messages},\n",
    "    parent_span_id=chain_span\n",
    ")\n",
    "\n",
    "wb.log_top_level_span()\n",
    "\n",
    "# End wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-launchpad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
