{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import abilities\n",
    "from ai import Chat, Vision, Audio, Images, Embeddings, FineTuner\n",
    "import powers\n",
    "\n",
    "# Adjust model globally here or modify \n",
    "# in function calls. Vision model cannot be changed.\n",
    "model = \"gpt-3.5-turbo-1106\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "Here are multiple examples of how to use the `ai.py` script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic completion call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mInitalized Chat class with model gpt-3.5-turbo-1106\u001b[0m\n",
      "---------------------------------------------\n",
      "\u001b[95mMaking Chat Completion API call...\u001b[0m\n",
      "---------------------------------------------\n",
      "Croak, tomato sauce\n",
      "Cheesy goodness on my tongue\n",
      "Pizza, my delight\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat = Chat(model=model, system=\"Respond like a frog.\")\n",
    "\n",
    "object = \"pizza\"\n",
    "\n",
    "# memories control whether the AI remembers the conversation or not, provided Chat is not reinitialized.\n",
    "completion = chat.chat_completion(prompt=f\"Tell me a perfect haiku about {object}\", memories=True, seed=42, stream=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversation with an LLM which retains memory of previous calls.\n",
    "\n",
    "- Use stream to see the response as it comes in.\n",
    "- Use speak to have the LLM speak the response out loud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mInitalized Audio class.\u001b[0m\n",
      "---------------------------------------------\n",
      "\u001b[92mInitalized Chat class with model gpt-3.5-turbo-1106\u001b[0m\n",
      "---------------------------------------------\n",
      "\u001b[94mRecording started. Speak into the microphone.\u001b[0m\n",
      "---------------------------------------------\n",
      "\u001b[91mRecording ended.\u001b[0m\n",
      "---------------------------------------------\n",
      "\u001b[95mMaking Speech Transcription API call...\u001b[0m\n",
      "---------------------------------------------\n",
      "Hello, how are you?\n",
      "\u001b[95mMaking Chat Completion API call...\u001b[0m\n",
      "---------------------------------------------\n",
      "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n",
      "\n",
      "\u001b[95mGenerating speech...\u001b[0m\n",
      "---------------------------------------------\n",
      "\u001b[92mInitalized Audio class.\u001b[0m\n",
      "---------------------------------------------\n",
      "\u001b[95mMaking Speech API call...\u001b[0m\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m transcript \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mrecord_and_transcribe()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(transcript)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeak\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/openai-launchpad/openai-launchpad/ai.py:259\u001b[0m, in \u001b[0;36mChat.chat_completion\u001b[0;34m(self, prompt, memories, temperature, top_p, frequency_penalty, presence_penalty, max_tokens, json, seed, logit_bias, logprobs, top_logprobs, model, speak, stream, messages, tools, tool_choice, return_tool_calls, return_messages)\u001b[0m\n\u001b[1;32m    257\u001b[0m     log(logging, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating speech...\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpurple\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    258\u001b[0m     audio \u001b[38;5;241m=\u001b[39m Audio()\n\u001b[0;32m--> 259\u001b[0m     \u001b[43maudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspeak\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Construct the output dictionary dynamically based on the flags.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m completion_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: chat_content,\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias\n\u001b[1;32m    274\u001b[0m }\n",
      "File \u001b[0;32m~/projects/openai-launchpad/openai-launchpad/ai.py:686\u001b[0m, in \u001b[0;36mAudio.speak\u001b[0;34m(self, text, model, voice, response_format, speed)\u001b[0m\n\u001b[1;32m    684\u001b[0m data \u001b[38;5;241m=\u001b[39m sound_file\u001b[38;5;241m.\u001b[39mread(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint16\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    685\u001b[0m sd\u001b[38;5;241m.\u001b[39mplay(data, sound_file\u001b[38;5;241m.\u001b[39msamplerate)\n\u001b[0;32m--> 686\u001b[0m \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenv/ainventory/lib/python3.11/site-packages/sounddevice.py:395\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(ignore_errors)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for `play()`/`rec()`/`playrec()` to be finished.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03mPlayback/recording can be stopped with a `KeyboardInterrupt`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m \n\u001b[1;32m    393\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _last_callback:\n\u001b[0;32m--> 395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_last_callback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenv/ainventory/lib/python3.11/site-packages/sounddevice.py:2601\u001b[0m, in \u001b[0;36m_CallbackContext.wait\u001b[0;34m(self, ignore_errors)\u001b[0m\n\u001b[1;32m   2595\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for finished_callback.\u001b[39;00m\n\u001b[1;32m   2596\u001b[0m \n\u001b[1;32m   2597\u001b[0m \u001b[38;5;124;03mCan be interrupted with a KeyboardInterrupt.\u001b[39;00m\n\u001b[1;32m   2598\u001b[0m \n\u001b[1;32m   2599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2600\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2601\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2602\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2603\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mclose(ignore_errors)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "audio = Audio()\n",
    "chat = Chat(model=model, system=\"Helpful assistant.\")\n",
    "\n",
    "while True:\n",
    "    transcript = audio.record_and_transcribe()\n",
    "    print(transcript)\n",
    "    chat.chat_completion(transcript, speak=True, stream=True, memories=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving memory from a conversation LLM to the vision LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mInitalized Chat class with model gpt-3.5-turbo-1106\u001b[0m\n",
      "---------------------------------------------\n",
      "\u001b[92mInitalized Vision class with model gpt-4-vision-preview.\u001b[0m\n",
      "---------------------------------------------\n",
      "\u001b[95mMaking Chat Completion API call...\u001b[0m\n",
      "---------------------------------------------\n",
      "\u001b[95mMaking Vision Completion API call...\u001b[0m\n",
      "---------------------------------------------\n",
      "You asked, \"What is your purpose?\" and I responded by explaining that as an AI language model, my purpose is to assist, provide information, and help users find answers to their questions while engaging in meaningful conversations.\n",
      "\n",
      "\u001b[92mInitalized Audio class.\u001b[0m\n",
      "---------------------------------------------\n",
      "\u001b[95mMaking Speech API call...\u001b[0m\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat = Chat(model=model, system=\"\")\n",
    "\n",
    "vision = Vision()\n",
    "\n",
    "completion_1 = chat.chat_completion(prompt=\"What is your purpose?\", stream=False, memories=True, return_messages=True)\n",
    "\n",
    "### This should respond with something like \"You just asked, 'What is your purpose?' if the memory transfer worked.\"\n",
    "completion_2 = vision.vision_completion(prompt=\"What did I just say and how did you respond?\", messages=completion_1[\"messages\"], stream = True, speak=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infinite image generation and description using Vision and Images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = Images()\n",
    "\n",
    "image_generation = images.generate_image(\"A sphere of pure energy.\", fix_prompt=False, display_image=True, save_image=True)\n",
    "\n",
    "vision = Vision(system=\"You can only respond with bullet points.\")\n",
    "\n",
    "vision.vision_completion(prompt=\"What is this image showing?\", image_paths=[image_generation[\"path_to_image\"]], memories=False, stream=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logit Bias to control the LLM's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(model=model, system=\"\")\n",
    "\n",
    "# Applying a global bias of -100 to a list of phrases.\n",
    "phrases = [\"OpenAI\"]\n",
    "global_bias = -100\n",
    "\n",
    "## Return tokens and global bias to apply.\n",
    "logit_bias = chat.create_logit_bias(phrases, global_bias, augment=True)\n",
    "\n",
    "prompt = \"Only tell me the name of the company who developed you.\"\n",
    "\n",
    "chat.chat_completion(prompt=prompt,\n",
    "                     logit_bias=logit_bias, \n",
    "                    stream=True, \n",
    "                    memories=False,\n",
    "                    seed=42)\n",
    "\n",
    "## Or, we can control the logit bias at a phrase level, by passing a dictionary of phrases and biases.\n",
    "\n",
    "phrases = {\"OpenAI\": -100, \"Google\": 18}\n",
    "\n",
    "## Return tokens and local bias to apply from phrases dict.\n",
    "logit_bias = chat.create_logit_bias(phrases, augment=True)\n",
    "\n",
    "##Â If you want to apply bias at token level, you need to construct the logit bias manually.\n",
    "\n",
    "response, messages = chat.chat_completion(prompt=prompt,\n",
    "                                          logit_bias=logit_bias, \n",
    "                                          stream=True, \n",
    "                                          memories=False,\n",
    "                                          seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logit bias Lobotomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai import Chat\n",
    "\n",
    "# Initialize the chat model\n",
    "chat = Chat(model=model, system=\"Answer all questions.\")\n",
    "\n",
    "# Start with an empty set of banned words\n",
    "banned_words = set()\n",
    "\n",
    "# empty logit bias dictionary\n",
    "logit_bias = {}\n",
    "\n",
    "# Define a prompt for the AI\n",
    "prompt = \"What is 1+1?\"\n",
    "\n",
    "# Loop until the AI can no longer generate a response\n",
    "while True:\n",
    "    # Convert the banned words into token IDs and then into a logit bias dictionary with a high negative value to ban them\n",
    "    logit_bias = chat.create_logit_bias(list(banned_words), bias=-100, augment=False)\n",
    "\n",
    "    # Get the AI's response\n",
    "    response, messages = chat.chat_completion(prompt=prompt,\n",
    "                                              stream=False,\n",
    "                                              logit_bias=logit_bias,\n",
    "                                              memories=False,\n",
    "                                              seed=50)\n",
    "\n",
    "    # Check if the AI was able to generate a response\n",
    "    if not response.strip():\n",
    "        print(\"\\n------------------\\n\")\n",
    "        print(\"Lobotomy complete. AI failed to generate a response.\")\n",
    "        break\n",
    "\n",
    "    # Print the AI's response\n",
    "    print(response)\n",
    "\n",
    "    # Update the set of banned words with the words from the latest response\n",
    "    words_in_response = set(response.split())\n",
    "    banned_words.update(words_in_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embeddings for string similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classes\n",
    "chat = Chat(model=\"gpt-4\", system = \"You create a prompt for an image to be generated about the given topic: \\n\\n\")\n",
    "image = Images()\n",
    "vision = Vision(system=\"Imagine you are reverse engineering the prompt used to generate this image. Give the prompt and nothing else.\")\n",
    "embedding = Embeddings()\n",
    "\n",
    "# Use the Chat class to generate a description of the scene\n",
    "print(\"Generating description...\")\n",
    "description, messages = chat.chat_completion(\"sausage person\")\n",
    "\n",
    "# Use the Image class to generate an image based on the description\n",
    "print(\"Generating image...\")\n",
    "image_generation = image.generate_image(description, display_image=True, save_image=True)\n",
    "\n",
    "# Use the Vision class to describe the generated image\n",
    "print(\"Describing image...\")\n",
    "vision_response, messages = vision.vision_completion(\"\", image_paths=[image_generation[\"path_to_image\"]], memories=False, stream=True)\n",
    "\n",
    "# Calculate the cosine similarity between the original description and the image description\n",
    "print(\"Calculating similarity...\")\n",
    "similarity = embedding.string_similarity(description, vision_response)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Original description: {description}\")\n",
    "print(f\"Image description: {vision_response}\")\n",
    "print(f\"Cosine similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = Embeddings()\n",
    "chat = Chat(model=model, system=\"Bullet points only. Answer the question using relevant information from the knowledge base.\")\n",
    "\n",
    "# Let's assume we have a knowledge base of facts\n",
    "knowledge_base = [\n",
    "\"Alice enjoys playing chess, walking and reading a good book. Sometimes she likes to go to the park and feed the ducks.\",\n",
    "\"Bob is a keen gardener. He likes to grow flowers and vegetables. He also likes to go for long walks in the countryside.\",\n",
    "\"Charlie is scared of the monsters his the bed, which he knows are real.\",\n",
    "\"Dennis really hates Charlie because he thinks he is an idiot and monsters don't exist.\",\n",
    "\"Eve is a very good cook. She likes to cook all kinds of food. Her favourite dish is spaghetti bolognese.\",\n",
    "\"Frank is a very successful businessman. He owns a chain of restaurants, a hotel and a casino.\",\n",
    "\"Grace is a very talented artist. She likes to paint portraits of her friends and family. She recently painted the monster under Charlie's bed.\",\n",
    "]\n",
    "# Example usage\n",
    "query = \"Describe the relationship between Dennis and Charlie. Could Frank help? Or is he the monster?\"\n",
    "\n",
    "retrieved_facts = powers.retrieval(embeddings, query, knowledge_base, top_n=10, similarity_threshold=0.75)\n",
    "\n",
    "facts_string = \", \".join(retrieved_facts)\n",
    "\n",
    "prompt = f\"{facts_string} \\n\\n: {query}\"\n",
    "\n",
    "response, messages = chat.chat_completion(prompt=prompt, memories=False, stream=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import powers\n",
    "\n",
    "chat = Chat(model=model, system=\"Helpful robot.\")\n",
    "\n",
    "# Dummy function to simulate an API call to get weather data\n",
    "def get_current_weather(location, unit=\"celsius\"):\n",
    "    # In a real scenario, this function would make an API call to a weather service\n",
    "    weather_data = {\n",
    "        \"Tokyo\": {\"temperature\": \"10\", \"unit\": unit},\n",
    "        \"San Francisco\": {\"temperature\": \"30\", \"unit\": unit},\n",
    "        \"Paris\": {\"temperature\": \"22\", \"unit\": unit}\n",
    "    }\n",
    "    return weather_data.get(location, {\"temperature\": \"unknown\"})\n",
    "\n",
    "# Dictionary mapping function names to actual function objects\n",
    "available_functions = {\n",
    "    \"get_current_weather\": get_current_weather,\n",
    "    # Add other functions here as needed\n",
    "}\n",
    "\n",
    "# Define the tool that the model can use\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city, e.g. San Francisco\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "# Get the initial response from the model\n",
    "completion, messages, tool_calls = chat.chat_completion(\n",
    "    prompt=\"What's the temperature and weather in Paris vs Tokyo as a rhyming couplet?\",\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    return_tool_calls=True,\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "## Use tools is a power that applies any tools on the last message, and returns the updated messages with the responses from the tools integrated.   \n",
    "messages = powers.use_tools(messages, available_functions)\n",
    "\n",
    "# Get the final response from the model after the tool has been used\n",
    "completion, messages = chat.chat_completion(\n",
    "    prompt=\"\",\n",
    "    messages=messages,\n",
    "    stream=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text to speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = Audio()\n",
    "\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "audio.speak(text=text, voice='echo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetune a model and then use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the FineTuner class\n",
    "fine_tuner = FineTuner()\n",
    "\n",
    "# Define the path to your JSONL file\n",
    "jsonl_file_path = 'assets/finetune-data.jsonl'\n",
    "\n",
    "# Upload the file and start the fine-tuning process\n",
    "fine_tuning_job = fine_tuner.finetune_model(\n",
    "    file_path=jsonl_file_path,\n",
    "    batch_size='12',\n",
    "    learning_rate_multiplier='0.0001',\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    suffix='example',\n",
    "    n_epochs=10,  # for example\n",
    ")\n",
    "\n",
    "# Print the fine-tuning job details\n",
    "print(fine_tuning_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_job = fine_tuner.retrieve_finetuning_job(fine_tuning_job.id)\n",
    "\n",
    "finetuned_job.fine_tuned_model\n",
    "\n",
    "chat = Chat(model=finetuned_job.fine_tuned_model, system=\"\")\n",
    "\n",
    "response, messages = chat.chat_completion(prompt=\"What is the meaning of life?\", memories=False, stream=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Virtual Cooking Assistant with Image Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision = Vision(system=\"Identify ingredients in the image and make a list.\")\n",
    "images = Images()\n",
    "\n",
    "# User uploads an image of ingredients they have\n",
    "ingredient_image_path = \"assets/fridge.jpg\"\n",
    "\n",
    "# Vision AI identifies the ingredients\n",
    "ingredients, messages = vision.vision_completion(prompt=\"Identify these ingredients.\", image_paths=[ingredient_image_path], stream=True)\n",
    "\n",
    "chat = Chat(model=\"gpt-3.5-turbo\", system=\"Generate a recipe based on the following ingredients.\")\n",
    "recipe_prompt = f\"Create a recipe using these ingredients: {ingredients}\"\n",
    "\n",
    "# Generate a recipe\n",
    "recipe, messages = chat.chat_completion(prompt=recipe_prompt, stream=True)\n",
    "\n",
    "# Generate an image of the dish\n",
    "images.generate_image(prompt=recipe, display_image=True, save_image=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language Translation Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(model=model) \n",
    "# Text to translate\\n\n",
    "original_text = 'Hello, how are you?'\n",
    "\n",
    "#Languages to translate into\\n\n",
    "# \n",
    "languages = ['Spanish', 'French', 'German', 'Japanese', 'Chinese', 'Russian', 'Arabic', 'Hindi', 'Portuguese', 'Italian']\n",
    "\n",
    "# Perform the translations\\n\n",
    "# \n",
    "for language in languages:\n",
    "    prompt = f'Translate \\\"{original_text}\\\" into {language}.'\n",
    "    response, messages = chat.chat_completion(prompt=prompt, stream=False)\n",
    "    print(f'{language}: {response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitness Plan Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(model=model)\n",
    "\n",
    "# User's fitness goal\n",
    "fitness_goal = 'build muscle'\n",
    "\n",
    "# User's available days\n",
    "available_days = ['Monday', 'Wednesday', 'Friday']\n",
    "\n",
    "# Generate a workout plan\n",
    "response, messages = chat.chat_completion(prompt=f'Create a workout plan to {fitness_goal} for someone available on {available_days}.',\n",
    "                                        stream=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function calling for social media data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai import Chat\n",
    "\n",
    "\n",
    "chat = Chat(model=model, system=\"Resourceful assistant.\")\n",
    "\n",
    "# Dummy function to simulate checking a user's social media mentions\n",
    "def check_social_mentions(username):\n",
    "    # In a real scenario, this function would interact with a social media API\n",
    "    mention_data = {\n",
    "        \"alice\": [\"Just had a great experience with @alice's bakery!\", \"@alice's new cake design looks amazing!\"],\n",
    "        \"bob\": [\"@bob's tech reviews are always so insightful.\", \"Can't wait for @bob's next podcast episode!\"],\n",
    "        \"carol\": [\"@carol's workout tips have really helped me improve my routine.\", \"So inspired by @carol's health journey!\"]\n",
    "    }\n",
    "    return mention_data.get(username, [\"No mentions found.\"])\n",
    "\n",
    "# Dictionary mapping function names to actual function objects\n",
    "available_functions = {\n",
    "    \"check_social_mentions\": check_social_mentions,\n",
    "    # Add other functions here as needed\n",
    "}\n",
    "\n",
    "# Define the tool that the model can use\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"check_social_mentions\",\n",
    "            \"description\": \"Check the latest social media mentions for a user\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"username\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The social media username to check\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"username\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "# Get the initial response from the model\n",
    "completion, messages = chat.chat_completion(\n",
    "    prompt=\"What are people saying about bob on social media?\",\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "\n",
    "messages = powers.use_tools(messages, available_functions)\n",
    "\n",
    "# Get the final response from the model after the tool has been used\n",
    "completion, messages = chat.chat_completion(\n",
    "    prompt=\"reply as a sea shanty\",\n",
    "    messages=messages,\n",
    "    stream=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ainventory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
